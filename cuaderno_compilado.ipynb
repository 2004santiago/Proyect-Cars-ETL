{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llamado a la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL\n",
    "url = \"https://api.eia.gov/v2/petroleum/pri/gnd/data/?frequency=weekly&data[0]=value&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=1000&api_key=bqwjaJLDl8NGnarM5gvFz7iDmIGNyKK47vtgmX91\"\n",
    "\n",
    "# Llamado a la API\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verifica si el llamado fue exitoso (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Convierte la respuesta a formato JSON\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extrae los datos relevantes (ajusta si es necesario según la estructura del JSON)\n",
    "    if 'response' in data and 'data' in data['response']:\n",
    "        records = data['response']['data']\n",
    "        \n",
    "        # Cargar los datos en un DataFrame de pandas\n",
    "        df = pd.DataFrame(records)\n",
    "        \n",
    "        # Muestra las primeras filas del DataFrame\n",
    "        print(df.head())\n",
    "        print(f\"Total de registros obtenidos: {len(df)}\")\n",
    "    else:\n",
    "        print(\"Error: La estructura del JSON no contiene los datos esperados.\")\n",
    "else:\n",
    "    print(f\"Error: Falló el llamado a la API con el código de estado {response.status_code}\")\n",
    "\n",
    "save = df.to_csv('Data/Raws/petroleum2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\"../Data/Raws/petroleum.csv\", delimiter=',',encoding='unicode_escape')\n",
    "\n",
    "############################################### Drop / Rename columns\n",
    "\n",
    "#Drop columns\n",
    "drop_columns = ['duoarea', 'units', 'series']  \n",
    "df = df.drop(columns=drop_columns)\n",
    "\n",
    "#Rename columns (value)\n",
    "df = df.rename(columns={'value': 'value($/GAL)'})\n",
    "\n",
    "############################################### Formats\n",
    "\n",
    "#Correct the types:\n",
    "df['period'] = pd.to_datetime(df['period'], format='%Y-%m-%d') #Object to date\n",
    "df = df.astype({col: 'string' for col in df.select_dtypes(include='object').columns}) #Object to string\n",
    "\n",
    "\n",
    "############################################### Cleaning / Replace values\n",
    "replaces = {\n",
    "    'PADD 5 EXCEPT CALIFORNIA': 'West Coast (except California)','PADD 4': 'Rocky Mountain',\n",
    "    'PADD 2': 'Midwest','PADD 5': 'West Coast','PADD 3': 'Gulf Coast','PADD 1C': 'East Coast (Central)',\n",
    "    'PADD 1B': 'East Coast (North)','PADD 1A': 'East Coast (South)','PADD 1': 'East Coast'\n",
    "} #Create a dictionary to replace the PADD values to a more explicit name\n",
    "df['area-name'] = df['area-name'].replace(replaces) #Replaces\n",
    "\n",
    "\n",
    "\n",
    "#Make a list for the codes to know if an area is city/state/region\n",
    "city_list = ['DENVER', 'NEW YORK CITY', 'SAN FRANCISCO', 'MIAMI', 'CLEVELAND', \n",
    "              'CHICAGO', 'SEATTLE', 'HOUSTON', 'LOS ANGELES', 'BOSTON']\n",
    "\n",
    "state_list = ['TEXAS', 'NEW YORK', 'COLORADO', 'CALIFORNIA', 'MINNESOTA', 'FLORIDA', 'MASSACHUSETTS', \n",
    "               'WASHINGTON', 'OHIO']\n",
    "\n",
    "region_list = ['West Coast (except California)', 'Rocky Mountain', 'Midwest', 'West Coast', \n",
    "               'Gulf Coast', 'East Coast (Central)', 'East Coast (North)', 'U.S.', \n",
    "               'East Coast (South)', 'East Coast']\n",
    "\n",
    "#Create the column 'area' based in 'area-name' values (If they are reffering to a city/state/region)\n",
    "df['area'] = np.where(df['area-name'].isin(city_list), 'City',\n",
    "               np.where(df['area-name'].isin(state_list), 'State', \n",
    "               np.where(df['area-name'].isin(region_list), 'Region', df['area-name'])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Make a list for the codes to gasoline/diesel\n",
    "gasoline_codes = ['EPM0', 'EPMM', 'EPMP', 'EPMR', 'EPMMR', 'EPMRR', 'EPM0R', 'EPMMU', 'EPMPR','EPMPU', 'EPM0U', 'EPMRU']\n",
    "diesel_codes = ['EPD2DXL0', 'EPD2D']\n",
    "\n",
    "#Replaces\n",
    "df['product'] = np.where(df['product'].isin(gasoline_codes), 'Gasoline', \n",
    "                np.where(df['product'].isin(diesel_codes), 'Diesel', df['product']))\n",
    "\n",
    "\n",
    "############################################### Nulls cleaning\n",
    "\n",
    "\n",
    "df.dropna(subset=['value($/GAL)'], inplace=True) #No nulls\n",
    "\n",
    "\n",
    "############################################### Save\n",
    "\n",
    "df.to_csv('../Data/Clean/petroleum_clean.csv', index=False)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "localhost = os.getenv('LOCALHOST')\n",
    "port = os.getenv('PORT')\n",
    "nameDB = os.getenv('DB_NAME')\n",
    "userDB = os.getenv('DB_USER')\n",
    "passDB = os.getenv('DB_PASS')\n",
    "\n",
    "  \n",
    "clean_table_database =  \"api_petroleum\"\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{userDB}:{passDB}@{localhost}:{port}/{nameDB}')\n",
    "\n",
    "try:\n",
    "    df.to_sql(clean_table_database, engine, if_exists='replace', index=False)\n",
    "    print(f\"Tabla '{clean_table_database}' actualizada correctamente.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al subir los datos: {e}\")\n",
    "\n",
    "finally:\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('Data/Clean/cars_clean.csv')\n",
    "apidf = pd.read_csv('Data/Clean/petroleum_clean.csv')\n",
    "\n",
    "\n",
    "############################################# DIMENSIONS FOR CARS DATASET\n",
    "\n",
    "# Car dim columns\n",
    "car_dim = df[['Year', 'Make', 'Model', 'Drivetrain', 'MinMPG', 'MaxMPG', \n",
    "                         'FuelType', 'Transmission', 'Engine', 'ExteriorColor', 'InteriorColor', \n",
    "                         'Used', 'VIN', 'Stock#']].drop_duplicates().reset_index(drop=True)\n",
    "# ID\n",
    "car_dim['ID_Car'] = car_dim.index + 1\n",
    "\n",
    "\n",
    "# Seller dim columns\n",
    "seller_dim = df[['SellerName', 'SellerType', 'State', 'Zipcode', 'StreetName']].drop_duplicates().reset_index(drop=True)\n",
    "#ID\n",
    "seller_dim['ID_Seller'] = seller_dim.index + 1\n",
    "\n",
    "\n",
    "# Rating dim columns\n",
    "rating_dim = df[['ConsumerRating', 'SellerRating', 'ComfortRating', 'InteriorDesignRating', \n",
    "                        'PerformanceRating', 'ValueForMoneyRating', 'ExteriorStylingRating', \n",
    "                        'ReliabilityRating', 'DealType']].drop_duplicates().reset_index(drop=True)\n",
    "# ID\n",
    "rating_dim['ID_Rating'] = rating_dim.index + 1\n",
    "\n",
    "\n",
    "# Merge original df with dimensions to asign IDs\n",
    "df_hechos_vendedor = pd.merge(df, seller_dim, on=['SellerName', 'SellerType', 'State', 'Zipcode', 'StreetName'], how='left')\n",
    "\n",
    "df_hechos_vehiculo = pd.merge(df, car_dim, on=['Year', 'Make', 'Model', 'Drivetrain', 'MinMPG', 'MaxMPG', \n",
    "                                                'FuelType', 'Transmission', 'Engine' ,'ExteriorColor', 'InteriorColor', \n",
    "                                                'Used', 'VIN', 'Stock#'], how='left')\n",
    "\n",
    "df_hechos_ratings = pd.merge(df, rating_dim, on=['ConsumerRating', 'SellerRating', 'ComfortRating','InteriorDesignRating', \n",
    "                                                        'PerformanceRating','ValueForMoneyRating', 'ExteriorStylingRating', \n",
    "                                                        'ReliabilityRating', 'DealType'], how='left')\n",
    "\n",
    "#Fact table columns\n",
    "tabla_hechos = df_hechos_vendedor[['Price', 'Mileage', 'ConsumerReviews', 'SellerReviews']].copy()\n",
    "\n",
    "# Add IDs from dimensions\n",
    "tabla_hechos['ID_Car'] = df_hechos_vehiculo['ID_Car']\n",
    "tabla_hechos['ID_Rating'] = df_hechos_ratings['ID_Rating']\n",
    "tabla_hechos['ID_Seller'] = df_hechos_vendedor['ID_Seller']\n",
    "\n",
    "# Sell ID\n",
    "tabla_hechos['ID_Sell'] = df.index + 1\n",
    "\n",
    "#Reorder the columns\n",
    "tabla_hechos = tabla_hechos[['ID_Sell', 'ID_Car', 'ID_Seller', 'ID_Rating', 'Price', \n",
    "                             'Mileage', 'ConsumerReviews', 'SellerReviews']]\n",
    "\n",
    "\n",
    "############################################# DIMENSIONS FOR API\n",
    "\n",
    "# Area dim columns\n",
    "area_dim = apidf[['area', 'area-name']].drop_duplicates().reset_index(drop=True)\n",
    "#ID\n",
    "area_dim['area_ID'] = area_dim.index + 1\n",
    "\n",
    "\n",
    "# Product dim\n",
    "product_dim = apidf[['product', 'product-name']].drop_duplicates().reset_index(drop=True)\n",
    "#ID\n",
    "product_dim['product_ID'] = product_dim.index + 1\n",
    "\n",
    "\n",
    "# Details dim columns\n",
    "details_dim = apidf[['process', 'process-name', 'series-description']].drop_duplicates().reset_index(drop=True)\n",
    "#ID\n",
    "details_dim['details_ID'] = details_dim.index + 1\n",
    "\n",
    "\n",
    "# Merge original df with dimensions to asign IDs\n",
    "df_fuel_area = pd.merge(apidf, area_dim, on=['area', 'area-name'], how='left')\n",
    "df_fuel_product = pd.merge(apidf, product_dim, on=['product', 'product-name'], how='left')\n",
    "df_fuel_details = pd.merge(apidf, details_dim, on=['process', 'process-name', 'series-description'], how='left')\n",
    "\n",
    "#Fact table columns\n",
    "fuel_fact = df_fuel_area[['period', 'value($/GAL)']].copy()\n",
    "\n",
    "# Add IDs from dimensions\n",
    "fuel_fact['area_ID'] = df_fuel_area['area_ID']\n",
    "fuel_fact['product_ID'] = df_fuel_product['product_ID']\n",
    "fuel_fact['details_ID'] = df_fuel_details['details_ID']\n",
    "\n",
    "# Fuel ID\n",
    "fuel_fact['fuel_ID'] = fuel_fact.index + 1\n",
    "\n",
    "#Reorder the columns\n",
    "fuel_fact = fuel_fact[['fuel_ID', 'period', 'area_ID', 'product_ID', 'details_ID', 'value($/GAL)']]\n",
    "\n",
    "\n",
    "\n",
    "# Guardar las tablas en archivos CSV\n",
    "tabla_hechos.to_csv('Data/Dimensional_model/sells_fact.csv', index=False)\n",
    "car_dim.to_csv('Data/Dimensional_model/car_dim.csv', index=False)\n",
    "seller_dim.to_csv('Data/Dimensional_model/seller_dim.csv', index=False)\n",
    "rating_dim.to_csv('Data/Dimensional_model/rating_dim.csv', index=False)\n",
    "\n",
    "# Guardar las tablas en archivos CSV\n",
    "fuel_fact.to_csv('Data/Dimensional_model/fuel_fact.csv', index=False)\n",
    "area_dim.to_csv('Data/Dimensional_model/area_dim.csv', index=False)\n",
    "product_dim.to_csv('Data/Dimensional_model/product_dim.csv', index=False)\n",
    "details_dim.to_csv('Data/Dimensional_model/details_dim.csv', index=False)\n",
    "\n",
    "\n",
    "############################################# SAVE IN DB\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Conexión a la base de datos\n",
    "localhost = os.getenv('LOCALHOST')\n",
    "port = os.getenv('PORT')\n",
    "nameDB = os.getenv('DB_NAME')\n",
    "userDB = os.getenv('DB_USER')\n",
    "passDB = os.getenv('DB_PASS')\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{userDB}:{passDB}@{localhost}:{port}/{nameDB}')\n",
    "\n",
    "csv_directory = 'Data/Dimensional_model'\n",
    "\n",
    "for csv_file in os.listdir(csv_directory):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        table_name = csv_file.replace('.csv', '')\n",
    "        \n",
    "        location_file = os.path.join(csv_directory, csv_file)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(location_file, sep=\",\")\n",
    "            \n",
    "            df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "            \n",
    "            print(f\"Tabla '{table_name}' creada y datos subidos exitosamente.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error al subir los datos del archivo '{csv_file}': {e}\")\n",
    "\n",
    "        finally:\n",
    "            engine.dispose()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
